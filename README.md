# ðŸ§  Local Research Assistant (RAG System)

A local Retrieval-Augmented Generation (RAG) research assistant that answers questions using your own documents with full source transparency.

## ðŸ”¹ Features
- Semantic document retrieval using FAISS
- Sentence-transformer embeddings
- LLaMA-powered answer generation via Ollama
- Source-aware responses with document references
- Interactive CLI mode

## ðŸ”¹ Tech Stack
- Python
- LangChain
- FAISS
- HuggingFace Embeddings
- Ollama (LLaMA)
- Retrival-Augmented Generation(RAG)

## ðŸ”¹ Project Structure

data/ # Input documents
faiss_index/ # Vector index
research_assistant.py
main.py
demo_outputs.json


## ðŸ”¹ How to Run

```bash
pip install -r requirements.txt
ollama run llama3
python main.py
